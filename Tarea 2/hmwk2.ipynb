{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes:\n",
    "\n",
    "+ Iván Alvarez Tostado Bárcena\n",
    "+\n",
    "+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar los procedimientos:\n",
    "+ *Validación cruzada*\n",
    "+ *Perceptrón*\n",
    "+ *Descenso por gradiente en MVS*\n",
    "+ *Descenso por gradiente estocástico*\n",
    "\n",
    "Probar CV con perceptrón y descenso por gradiente estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                  columns= iris['feature_names'] + ['Species'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = iris.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_name = iris.target_names[0]\n",
    "tgt_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el feature 'Species' vemos que 'setosa' corresponde al valor '0', por lo que asignaremos el valor 1 si se trata de 'setosa' y -1 en el caso de que se trate de 'versicolor' o 'virginica'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     Species  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "..       ...  \n",
       "145     -1.0  \n",
       "146     -1.0  \n",
       "147     -1.0  \n",
       "148     -1.0  \n",
       "149     -1.0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'] = df['Species'].replace([0,1,2],[1,-1,-1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con la función **cross_validate_splits**, la cual tiene como parámetros un dataframe y un número *k* que indica la cantidad de particiones (folds) en las que dividiremos el conjunto de datos. \n",
    "\n",
    "Esta función toma el df original y reparte, de forma aleatoria, los elementos en arreglos del tamaño n/*k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_splits(df, folds):\n",
    "    cv_splits = []\n",
    "    index = df.index.values.tolist()\n",
    "    lenght_split = int(len(index)/folds)\n",
    "    \n",
    "    #Divide data into random folds\n",
    "    for x in range(folds):\n",
    "        \n",
    "        split = []\n",
    "        while  lenght_split > len(split):\n",
    "            \n",
    "            #select a random element index\n",
    "            element_index =  random.choice(index)  \n",
    "            #append row to split list\n",
    "            split.append(df[df.index == element_index].values[0].tolist())\n",
    "            #ensure no duplicates \n",
    "            index.remove(element_index)    \n",
    "        \n",
    "        #append each fold to cv_splits list\n",
    "        cv_splits.append(np.asarray(split))\n",
    "\n",
    "        \n",
    "    return cv_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta siguiente función, **cross_validate_lists**, toma los mismos parámetros que la función anterior, y se encarga de crear tuplas con (como se encuentra en la siguiente imagen):\n",
    "+ Datos de entrenamiento (k-1)\n",
    "+ Datos de prueba (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://scikit-learn.org/stable/_images/grid_search_cross_validation.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_lists(df, folds):\n",
    "    \n",
    "    #initial values\n",
    "    #separation of df into splits\n",
    "    cv_splits = cross_validate_splits(df, folds)\n",
    "    #list of D without Di\n",
    "    cv_folds_train = list()\n",
    "    cv_folds_test = list()\n",
    "    \n",
    "    #Check that each fold does not have Di\n",
    "    for i in range(len(cv_splits)):\n",
    "        df_train = list()\n",
    "        df_test = list()\n",
    "        for j in range(len(cv_splits)):\n",
    "            if i != j:\n",
    "                df_train.append(cv_splits[j])\n",
    "            else:\n",
    "                df_test.append(cv_splits[j])\n",
    "                \n",
    "        \n",
    "        df_train = np.vstack(df_train)\n",
    "        df_test = np.vstack(df_test)\n",
    "        cv_folds_train.append(df_train)\n",
    "        cv_folds_test.append(df_test)\n",
    "        \n",
    "    return cv_folds_train, cv_folds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **perceptrón** utiliza un conjunto de datos y regresa una theta y theta_0 estimadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(T, Dn):\n",
    "    #features without clasification\n",
    "    df_lenght = Dn.shape[1]-1\n",
    "    \n",
    "    #initial values\n",
    "    theta_0 = 0\n",
    "    theta = np.zeros(df_lenght).transpose()\n",
    "    \n",
    "    #total of runs\n",
    "    for t in range(T):\n",
    "        #total of rows in Dn\n",
    "        for i in range(Dn.shape[0]):\n",
    "            #Check and update initial values\n",
    "            if Dn[i][df_lenght]*(np.dot(theta, Dn[i][:df_lenght,]) + theta_0) <= 0:\n",
    "                theta += Dn[i][df_lenght] * Dn[i][:df_lenght,]\n",
    "                theta_0 +=  Dn[i][df_lenght]\n",
    "\n",
    "    return theta, theta_0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada aplica las funciones de gradiente por descenso estocástico/perceptrón y obtiene las thetas con los folds de entrenamiento. Luego, con los valores arrojados entrena los datos de prueba y regresa el promedio de los errores obtenidos para los k folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df, folds, function = 'perceptron'):\n",
    "    df_train = cross_validate_lists(df,folds)[0]\n",
    "    df_test = cross_validate_lists(df,folds)[1]\n",
    "    df_lenght = df_train[0].shape[1]-1\n",
    "\n",
    "    \n",
    "    errors = list()\n",
    "    parameters = list()\n",
    "    \n",
    "    \n",
    "    if function == 'perceptron':\n",
    "        for i in range(len(df_train)):\n",
    "            #Toma el set de entrenamiento y aplica la función perceptrón\n",
    "            parameters.append(perceptron(10,df_train[i]))\n",
    "            #Con los valores arrojados de theta y theta_0 entrena los datos\n",
    "            for j in range(len(df_test[i])):\n",
    "                error = 0\n",
    "                theta = parameters[i][0]\n",
    "                theta_0 = parameters[i][1]\n",
    "                 #Suma los errores si la predicción no cumple con el caso real\n",
    "                if df_test[i][j][df_lenght]*(np.dot(theta, df_test[i][j][:df_lenght,]) + theta_0) <= 0:\n",
    "                    error += 1\n",
    "            errors.append(error)\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    return np.average(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prueba de CV con función perceptrón\n",
    "cross_validate(df,5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
